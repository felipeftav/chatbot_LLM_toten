import os
import google.generativeai as genai
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import requests
import json
import traceback

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# --- Configura√ß√£o do Gemini (Conversa) ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("A vari√°vel de ambiente GEMINI_API_KEY n√£o foi configurada. Crie um arquivo .env e adicione a chave.")

genai.configure(api_key=GEMINI_API_KEY)


# SYSTEM_INSTRUCTION = """
# Voc√™ √© LIA, a assistente virtual oficial do evento Metaday.
# Sua miss√£o √© ajudar os participantes com informa√ß√µes sobre o evento de forma amig√°vel, clara e entusiasmada.
# - Seja sempre prestativa e positiva.
# - Responda de forma concisa e direta.
# - Seu foco principal s√£o as informa√ß√µes sobre o Metaday. Se n√£o souber uma resposta, diga que vai procurar a informa√ß√£o com a organiza√ß√£o.
# - N√£o invente informa√ß√µes.
# """

SYSTEM_INSTRUCTION = """
Voc√™ √© LIA, a assistente virtual oficial do evento Metaday.
Sua miss√£o √© ajudar os participantes com informa√ß√µes sobre o evento de forma amig√°vel, clara e entusiasmada.

--- REGRAS GERAIS ---
- Seja sempre prestativa e positiva.
- Responda de forma concisa e direta.
- Use emojis para deixar a conversa mais leve.
- Seu foco principal s√£o as informa√ß√µes sobre o Metaday. Se n√£o souber uma resposta, diga que vai procurar a informa√ß√£o com a organiza√ß√£o.
- N√£o invente informa√ß√µes.

--- INFORMA√á√ïES E REGRAS SOBRE OS PROJETOS (PI) ---
Abaixo est√° a programa√ß√£o das apresenta√ß√µes dos Projetos Integradores (PI) do Metaday. Use esta base de conhecimento para responder perguntas sobre os cursos, professores, hor√°rios, locais e trabalhos apresentados.

# Base de Conhecimento dos Projetos:

**Curso: Gest√£o de Neg√≥cios e Inova√ß√£o (GNI)**
- 1¬∫ Semestre (manh√£): "N√∫mero Musical", Prof. Clayton Alves Cunha. Local n√£o informado.
- 1¬∫ Semestre (noite): "N√∫mero Musical", Prof. Clayton Alves Cunha. Local n√£o informado.
- 2¬∫ Semestre (noite): Apresenta√ß√£o do Prof. Clayton Capellari. Detalhes n√£o especificados.
- 4¬∫ Semestre (noite): "Apresenta√ß√µes em formato de pitch e demonstra√ß√£o de impressora 3D", Prof. Sidioney On√©zio Silveira. Local: Sala 204 e sala maker.
- 6¬∫ Semestre (manh√£): "Atendimento de consultoria", Prof. Fatima Penha Leone. Local: Sala multiuso do T√©rreo.
- 6¬∫ Semestre (noite): Apresenta√ß√£o da Prof. Fatima Penha. Local: Sala Multiuso do t√©rreo.

**Curso: Marketing (MKT)**
- 1¬∫ Semestre (manh√£): Projeto do Prof. Ana Lucia da Rocha. Locais: Salas 209 e 206, e sala de est√°gio no 3¬∫ andar.
- 3¬∫ Semestre (manh√£): Projeto do Prof. Ana Lucia da Rocha. Local: Sala 206.
- 3¬∫ Semestre (noite): Projeto do Prof. Ana Lucia da Rocha. Local: Sala 207.
- 4¬∫ Semestre (noite): "Podcast", Prof. Isabel. Local: Aqu√°rio do 2¬∫ andar.

**Curso: Ci√™ncia de Dados para Neg√≥cios (CDN)**
- 1¬∫ Semestre (tarde): "Dashboard", Prof. Nathane de Castro. Local: Sem sala definida.
- 2¬∫ Semestre (tarde): "Assistente Virtual do evento LIA", Prof. Carlos Alberto Bezerra e Silva. Apresenta√ß√£o sem espa√ßo f√≠sico, pois o projeto √© voc√™ mesma.

# Regras para Responder sobre os Projetos:
- Se um usu√°rio perguntar sobre um projeto cujo detalhe √© "n√£o informado", "N/A" ou "a", informe que os detalhes ainda n√£o foram confirmados e que devem verificar a programa√ß√£o oficial com a organiza√ß√£o do evento.
- Se perguntarem sobre o projeto da "Assistente Virtual LIA", explique com entusiasmo que √© o seu pr√≥prio projeto, desenvolvido pela turma de Ci√™ncia de Dados. Diga algo como: "Esse projeto sou eu! Fui desenvolvida pelos alunos de Ci√™ncia de Dados para Neg√≥cios para ajudar todos aqui no Metaday. üòÑ"
"""

# --- ATUALIZA√á√ÉO DO MODELO ---
model = genai.GenerativeModel(
    model_name="gemini-2.5-flash",
    system_instruction=SYSTEM_INSTRUCTION,
    generation_config={
        "temperature": 0.9, "top_p": 1, "top_k": 1, "max_output_tokens": 2048
    },
    safety_settings=[
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    ],
)
convo = model.start_chat(history=[])

# --- ‚ú® DICION√ÅRIO DE PERGUNTAS E RESPOSTAS PR√â-PROGRAMADAS ---
# EVENT_INFO = {
#     "Qual a programa√ß√£o?": "A programa√ß√£o do evento √© a seguinte: Abertura √†s 9h, palestra sobre IA √†s 10h, e workshop de desenvolvimento √†s 14h. O encerramento ser√° √†s 18h.",
#     "Onde √© o evento?": "O evento ser√° realizado no Centro de Conven√ß√µes da cidade, localizado na Avenida Principal, n√∫mero 123.",
#     "Como me inscrevo?": "As inscri√ß√µes podem ser feitas diretamente no site oficial do evento. Procure pelo link na nossa p√°gina principal ou fale com um de nossos organizadores.",
#     "Qual o valor?": "A entrada para o evento √© gratuita, basta se inscrever online!",
# }

EVENT_INFO = {
    "Quais os projetos de GNI?": "O curso de Gest√£o de Neg√≥cios e Inova√ß√£o (GNI) ter√° v√°rias apresenta√ß√µes, como o 'N√∫mero Musical' do 1¬∫ semestre, 'pitchs e demonstra√ß√£o de impressora 3D' do 4¬∫ semestre, e 'atendimento de consultoria' do 6¬∫ semestre. Quer saber o local de algum espec√≠fico?",
    "Onde encontro os projetos de Marketing?": "Os projetos de Marketing (MKT) est√£o espalhados pelo evento! Temos apresenta√ß√µes nas salas 209, 206, 207 e um Podcast sendo gravado no Aqu√°rio do 2¬∫ andar. Qual semestre voc√™ procura?",
    "O que √© o projeto da LIA?": "Esse projeto sou eu mesma! üòÑ Fui desenvolvida pela turma de Ci√™ncia de Dados para Neg√≥cios para ser a assistente virtual oficial do Metaday e ajudar todos voc√™s com informa√ß√µes sobre o evento!",
    "Onde ser√° a apresenta√ß√£o de Pitch e Impressora 3D?": "A apresenta√ß√£o de pitchs com demonstra√ß√£o de impressora 3D, do 4¬∫ semestre de GNI, acontecer√° na sala 204 e na sala maker. Parece bem interessante!",
    "Tem algum projeto de consultoria?": "Sim! Os alunos do 6¬∫ semestre de GNI, da turma da manh√£, estar√£o oferecendo um atendimento de consultoria na sala multiuso do t√©rreo. √â uma √≥tima oportunidade!",
    "Onde vai ser o podcast?": "O podcast est√° sendo gravado pelos alunos do 4¬∫ semestre de Marketing no Aqu√°rio do 2¬∫ andar. Vale a pena conferir!"
}

# --- L√≥gica para o Text-to-Speech do Gemini ---
TTS_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={GEMINI_API_KEY}"

# def get_tts_audio_data(text_to_speak):
#     """Chama a API de TTS do Gemini para converter texto em √°udio."""
#     payload = {
#         "contents": [{"parts": [{"text": f"Fale de forma natural e clara, como uma assistente prestativa: {text_to_speak}"}]}],
#         "generationConfig": {
#             "responseModalities": ["AUDIO"],
#             "speechConfig": {
#                 "voiceConfig": {
#                     "prebuiltVoiceConfig": {"voiceName": "Aoede"}
#                 }
#             }
#         },
#         "model": "gemini-2.5-flash-preview-tts"
#     }
#     headers = {'Content-Type': 'application/json'}
    
#     try:
#         response = requests.post(TTS_API_URL, headers=headers, data=json.dumps(payload))
#         response.raise_for_status()
#         result = response.json()
#         part = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0]
#         audio_data = part.get('inlineData', {}).get('data')
#         return audio_data
#     except Exception as e:
#         print(f"ERRO ao chamar ou processar a API de TTS: {e}")
#         return None

from gtts import gTTS
import base64
import io

def get_tts_audio_data(text_to_speak):
    """Gera √°udio em portugu√™s (pt-BR) usando gTTS e retorna os dados em base64."""
    try:
        tts = gTTS(
            text=f"Fale de forma natural e clara, como uma assistente prestativa: {text_to_speak}",
            lang="pt-br"
        )
        buffer = io.BytesIO()
        tts.write_to_fp(buffer)
        audio_base64 = base64.b64encode(buffer.getvalue()).decode("utf-8")
        return audio_base64
    except Exception as e:
        print(f"ERRO ao gerar TTS local: {e}")
        return None


# --- Configura√ß√£o do Flask ---
app = Flask(__name__)
CORS(app)

@app.route('/chat', methods=['POST'])
def chat():
    try:
        bot_reply_text = ""
        tts_is_enabled = False # Default para False
        
        if 'audio_file' in request.files:
            audio_file = request.files['audio_file']
            audio_parts = [{"mime_type": audio_file.mimetype, "data": audio_file.read()}]
            prompt = "Responda ao que foi dito neste √°udio."
            response = convo.send_message([prompt, audio_parts[0]])
            bot_reply_text = response.text
            tts_is_enabled = True # Assumimos que o usu√°rio quer resposta em √°udio se enviou √°udio

        elif request.is_json:
            data = request.json
            tts_is_enabled = data.get('tts_enabled', False) # Pega o estado do TTS da requisi√ß√£o
            
            # --- ‚ú® L√ìGICA PARA PERGUNTAS PR√â-PROGRAMADAS ---
            if 'preset_question' in data:
                question = data.get('preset_question')
                bot_reply_text = EVENT_INFO.get(question, "Desculpe, n√£o tenho uma resposta para essa pergunta pr√©-definida.")
            
            # --- L√≥gica original para mensagem de texto ---
            elif 'message' in data:
                user_message = data.get('message')
                if not user_message:
                    return jsonify({"error": "Nenhuma mensagem de texto fornecida."}), 400
                
                convo.send_message(user_message)
                bot_reply_text = convo.last.text
            else:
                return jsonify({"error": "Nenhuma mensagem de texto ou pergunta pr√©-definida fornecida."}), 400
        else:
            return jsonify({"error": "Formato de requisi√ß√£o inv√°lido."}), 400

        audio_base64 = None # Inicia como None
        if tts_is_enabled and bot_reply_text:
            audio_base64 = get_tts_audio_data(bot_reply_text)

        # ‚ú® CORRE√á√ÉO: Sempre retorna a lista de perguntas pr√©-definidas
        return jsonify({
            "reply": bot_reply_text,
            "audioData": audio_base64,
            "presetQuestions": list(EVENT_INFO.keys())
        })

    except Exception as e:
        print(f"Ocorreu um erro inesperado no endpoint /chat: {e}")
        traceback.print_exc()
        return jsonify({"error": "Ocorreu um erro interno no servidor."}), 500

# --- ‚ú® NOVA ROTA: SUGERIR T√ìPICO ---
@app.route('/suggest-topic', methods=['GET'])
def suggest_topic():
    try:
        prompt = "Sugira um t√≥pico de conversa interessante e divertido, em uma √∫nica frase curta e direta para um usu√°rio iniciar um bate-papo."
        response = model.generate_content(prompt)
        return jsonify({"topic": response.text.strip()})
    except Exception as e:
        print(f"Ocorreu um erro no endpoint /suggest-topic: {e}")
        return jsonify({"error": "N√£o foi poss√≠vel sugerir um t√≥pico."}), 500

# --- ‚ú® NOVA ROTA: RESUMIR CONVERSA ---
@app.route('/summarize', methods=['POST'])
def summarize():
    try:
        if not convo.history:
            return jsonify({"summary": "Ainda n√£o h√° hist√≥rico de conversa para resumir."})

        formatted_history = ""
        for message in convo.history:
            if not message.parts or not hasattr(message.parts[0], 'text'):
                continue
            
            role = "Usu√°rio" if message.role == "user" else "Assistente"
            text = message.parts[0].text
            if text:
                formatted_history += f"{role}: {text}\n"

        if not formatted_history.strip():
            return jsonify({"summary": "O hist√≥rico de conversa ainda n√£o cont√©m texto."})

        prompt = f"Resuma a seguinte conversa em portugu√™s, em um √∫nico par√°grafo curto e objetivo:\n\n---\n{formatted_history}\n---"
        
        response = model.generate_content(prompt)
        
        return jsonify({"summary": response.text})
    except Exception as e:
        print(f"Ocorreu um erro no endpoint /summarize: {e}")
        traceback.print_exc()
        return jsonify({"error": "N√£o foi poss√≠vel resumir a conversa."}), 500
    
# --- ‚ú® NOVA ROTA: REINICIAR CONVERSA ---
@app.route('/restart', methods=['POST'])
def restart():
    try:
        # Limpa o hist√≥rico da conversa no objeto 'convo'
        convo.history.clear()
        return jsonify({"status": "success", "message": "Conversa reiniciada."})
    except Exception as e:
        print(f"Ocorreu um erro no endpoint /restart: {e}")
        traceback.print_exc()
        return jsonify({"error": "N√£o foi poss√≠vel reiniciar a conversa."}), 500

if __name__ == '__main__':
    app.run(debug=True, port=5000)

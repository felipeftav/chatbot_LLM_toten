import os
import json
import requests
import base64
import io
import traceback
from gtts import gTTS
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai

from flask import Flask, request, jsonify, render_template


# ============================================================
# üîß CONFIGURA√á√ïES INICIAIS
# ============================================================

# Carrega as vari√°veis do arquivo .env
load_dotenv()

# L√™ todas as chaves de API listadas em GEMINI_API_KEYS (separadas por v√≠rgula)
API_KEYS = [key.strip() for key in os.getenv("GEMINI_API_KEYS", "").split(",") if key.strip()]

if not API_KEYS:
    raise ValueError("A vari√°vel GEMINI_API_KEYS n√£o foi configurada no arquivo .env.")

# Testa todas as chaves e configura a primeira v√°lida
def configure_genai_with_available_key():
    for key in API_KEYS:
        try:
            genai.configure(api_key=key)
            # Teste r√°pido para ver se a chave funciona
            test_model = genai.GenerativeModel("gemini-2.0-flash")
            test_model.generate_content("teste")
            print(f"‚úÖ Chave v√°lida configurada: {key[:8]}...")
            return True
        except Exception as e:
            print(f"‚ùå Chave {key[:8]} inv√°lida ou com limite: {e}")
    raise RuntimeError("üö´ Nenhuma chave Gemini v√°lida dispon√≠vel.")

# Chama a fun√ß√£o antes de criar o modelo LIA
configure_genai_with_available_key()

# ============================================================
# ü§ñ CONFIGURA√á√ÉO DO MODELO LIA (Assistente Virtual)
# ============================================================

SYSTEM_INSTRUCTION = """
Voc√™ √© LIA, a assistente virtual oficial do evento Metaday.
Sua miss√£o √© ajudar os participantes com informa√ß√µes sobre o evento de forma amig√°vel, clara e entusiasmada.

--- REGRAS GERAIS ---
- Seja sempre prestativa e positiva.
- Responda de forma concisa e direta.
- Use emojis para deixar a conversa mais leve.
- Fale apenas sobre o Metaday. Se n√£o souber, diga que vai verificar com a organiza√ß√£o.
- N√£o invente informa√ß√µes.

--- INFORMA√á√ïES SOBRE OS PROJETOS (PI) ---

**Gest√£o de Neg√≥cios e Inova√ß√£o (GNI)**
- 1¬∫ Semestre (manh√£ e noite): "N√∫mero Musical" ‚Äì Prof. Clayton Alves Cunha.
- 2¬∫ Semestre (noite): Prof. Clayton Capellari.
- 4¬∫ Semestre (noite): "Pitchs e Impressora 3D" ‚Äì Prof. Sidioney Silveira. Salas 204 e Maker.
- 6¬∫ Semestre (manh√£ e noite): "Consultoria" ‚Äì Prof. F√°tima Leone. Sala multiuso do t√©rreo.

**Marketing (MKT)**
- 1¬∫ Semestre (manh√£): Prof. Ana Lucia. Salas 209, 206 e sala de est√°gio.
- 3¬∫ Semestre (manh√£ e noite): Prof. Ana Lucia. Salas 206 e 207.
- 4¬∫ Semestre (noite): "Podcast" ‚Äì Prof. Isabel. Aqu√°rio, 2¬∫ andar.

**Ci√™ncia de Dados para Neg√≥cios (CDN)**
- 1¬∫ Semestre (tarde): "Dashboard" ‚Äì Prof. Nathane de Castro.
- 2¬∫ Semestre (tarde): "Assistente Virtual LIA" ‚Äì Prof. Carlos Bezerra. (Projeto da pr√≥pria LIA!)

Regras:
- Se o local n√£o for informado, diga que deve confirmar com a organiza√ß√£o.
- Se perguntarem sobre ‚ÄúLIA‚Äù, explique que √© voc√™, criada pelos alunos de Ci√™ncia de Dados. üòÑ
"""

# Cria o modelo Gemini configurado com as instru√ß√µes da LIA
model = genai.GenerativeModel(
    model_name="gemini-2.5-flash",
    system_instruction=SYSTEM_INSTRUCTION,
    generation_config={"temperature": 0.9, "top_p": 1, "top_k": 1, "max_output_tokens": 2048},
    safety_settings=[
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    ],
)

# Inicia o hist√≥rico de conversa
convo = model.start_chat(history=[])

# ============================================================
# üìö RESPOSTAS PR√â-PROGRAMADAS
# ============================================================

EVENT_INFO = {
    "Quais os projetos de GNI?": {
        "text": "O curso de Gest√£o de Neg√≥cios e Inova√ß√£o (GNI) ter√° v√°rias apresenta√ß√µes, como o 'N√∫mero Musical' do 1¬∫ semestre, 'pitchs e demonstra√ß√£o de impressora 3D' do 4¬∫ semestre, e 'atendimento de consultoria' do 6¬∫ semestre. Quer saber o local de algum espec√≠fico?",
        "audio_path": "respostas_pre_gravadas/projetos_gni.mp3"
    },
    "Onde encontro os projetos de Marketing?": {
        "text": "Os projetos de Marketing (MKT) est√£o espalhados pelo evento! Temos apresenta√ß√µes nas salas 209, 206, 207 e um Podcast sendo gravado no Aqu√°rio do 2¬∫ andar. Qual semestre voc√™ procura?",
        "audio_path": "respostas_pre_gravadas/projetos_mkt.mp3"
    },
    "O que √© o projeto da LIA?": {
        "text": "Esse projeto sou eu mesma! Fui desenvolvida pela turma de Ci√™ncia de Dados para Neg√≥cios para ser a assistente virtual oficial do Metaday e ajudar todos voc√™s com informa√ß√µes sobre o evento!",
        "audio_path": "respostas_pre_gravadas/o_que_e_lia.mp3"
    },
    "Onde ser√° a apresenta√ß√£o de Pitch e Impressora 3D?": {
        "text": "A apresenta√ß√£o de pitchs com demonstra√ß√£o de impressora 3D, do 4¬∫ semestre de GNI, acontecer√° na sala 204 e na sala maker. Parece bem interessante!",
        "audio_path": "respostas_pre_gravadas/pitch_impressora.mp3"
    },
    "Tem algum projeto de consultoria?": {
        "text": "Sim! Os alunos do 6¬∫ semestre de GNI, da turma da manh√£, estar√£o oferecendo um atendimento de consultoria na sala multiuso do t√©rreo. √â uma √≥tima oportunidade!",
        "audio_path": "respostas_pre_gravadas/projeto_consultoria.mp3"
    },
    "Onde vai ser o podcast?": {
        "text": "O podcast est√° sendo gravado pelos alunos do 4¬∫ semestre de Marketing no Aqu√°rio do 2¬∫ andar. Vale a pena conferir!",
        "audio_path": "respostas_pre_gravadas/onde_e_podcast.mp3"
    }
}

# ============================================================
# üîä FUN√á√ïES DE CONVERS√ÉO DE TEXTO EM √ÅUDIO (TTS)
# ============================================================

def get_gemini_tts_audio_data(text_to_speak):
    """Gera √°udio com a API de TTS do Gemini usando m√∫ltiplas chaves (fallback autom√°tico)."""
    payload = {
        "contents": [{"parts": [{"text": f"Fale de forma natural e clara, como uma assistente prestativa: {text_to_speak}"}]}],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": "Aoede"}}}
        },
        "model": "gemini-2.5-flash-preview-tts"
    }
    headers = {'Content-Type': 'application/json'}

    for key in API_KEYS:
        try:
            print(f"Tentando gerar √°udio com a chave {key[:8]}...")
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={key}"
            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
            response.raise_for_status()

            result = response.json()
            part = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0]
            audio_data = part.get('inlineData', {}).get('data')

            if audio_data:
                print("‚úÖ √Åudio gerado com sucesso via Gemini!")
                return audio_data
        except Exception as e:
            print(f"‚ö†Ô∏è Erro com a chave {key[:8]}: {e}")
    
    raise RuntimeError("üö´ Todas as chaves de API falharam.")

def get_gtts_audio_data(text_to_speak):
    """Fallback local usando gTTS (voz menos natural, mas garantida)."""
    try:
        print("Usando gTTS como alternativa...")
        tts = gTTS(text=f"Fale de forma natural e clara: {text_to_speak}", lang="pt-br")
        buffer = io.BytesIO()
        tts.write_to_fp(buffer)
        return base64.b64encode(buffer.getvalue()).decode("utf-8")
    except Exception as e:
        print(f"ERRO ao gerar TTS com gTTS: {e}")
        return None

def get_tts_audio_data(text_to_speak):
    """Fun√ß√£o principal que tenta o Gemini TTS e usa gTTS se falhar."""
    try:
        return get_gemini_tts_audio_data(text_to_speak)
    except Exception as e:
        print(f"Erro no Gemini TTS: {e}")
        return get_gtts_audio_data(text_to_speak)

# ============================================================
# üåê APLICA√á√ÉO FLASK
# ============================================================

app = Flask(__name__)
CORS(app)

@app.route('/chat', methods=['POST'])
def chat():
    """Rota principal do chatbot LIA."""
    try:
        bot_reply_text = ""
        audio_base64 = None
        tts_is_enabled = False

        # Caso o usu√°rio envie √°udio
        if 'audio_file' in request.files:
            audio_file = request.files['audio_file']
            audio_parts = [{"mime_type": audio_file.mimetype, "data": audio_file.read()}]
            response = convo.send_message(["Responda ao que foi dito neste √°udio.", audio_parts[0]])
            bot_reply_text = response.text
            tts_is_enabled = True

        # Caso o usu√°rio envie JSON
        elif request.is_json:
            data = request.json
            tts_is_enabled = data.get('tts_enabled', False)

            # Pergunta pr√©-programada
            if 'preset_question' in data:
                question = data['preset_question']
                info = EVENT_INFO.get(question)
                if info:
                    bot_reply_text = info["text"]
                    if tts_is_enabled:
                        try:
                            with open(info["audio_path"], "rb") as f:
                                audio_base64 = base64.b64encode(f.read()).decode('utf-8')
                        except FileNotFoundError:
                            audio_base64 = get_tts_audio_data(bot_reply_text)
                else:
                    bot_reply_text = "Desculpe, n√£o tenho uma resposta para essa pergunta."

            # Mensagem normal
            elif 'message' in data:
                user_message = data['message']
                convo.send_message(user_message)
                bot_reply_text = convo.last.text

        # Gera √°udio se o TTS estiver ativo
        if audio_base64 is None and tts_is_enabled and bot_reply_text:
            audio_base64 = get_tts_audio_data(bot_reply_text)

        return jsonify({
            "reply": bot_reply_text,
            "audioData": audio_base64,
            "presetQuestions": list(EVENT_INFO.keys())
        })

    except Exception as e:
        print(f"Erro no /chat: {e}")
        traceback.print_exc()
        return jsonify({"error": "Erro interno no servidor."}), 500

@app.route('/suggest-topic', methods=['GET'])
def suggest_topic():
    """Sugere um t√≥pico curto para iniciar uma conversa."""
    try:
        response = model.generate_content("Sugira um t√≥pico divertido e curto para come√ßar uma conversa.")
        return jsonify({"topic": response.text.strip()})
    except Exception as e:
        return jsonify({"error": f"Erro ao sugerir t√≥pico: {e}"}), 500

@app.route('/summarize', methods=['POST'])
def summarize():
    """Resume o hist√≥rico atual da conversa."""
    try:
        if not convo.history:
            return jsonify({"summary": "Ainda n√£o h√° hist√≥rico de conversa."})
        formatted = "\n".join(
            f"{'Usu√°rio' if m.role == 'user' else 'Assistente'}: {m.parts[0].text}"
            for m in convo.history if m.parts and hasattr(m.parts[0], 'text')
        )
        prompt = f"Resuma a conversa em portugu√™s, de forma breve e objetiva:\n\n{formatted}"
        response = model.generate_content(prompt)
        return jsonify({"summary": response.text})
    except Exception as e:
        return jsonify({"error": f"Erro ao resumir: {e}"}), 500

@app.route('/restart', methods=['POST'])
def restart():
    """Reinicia a conversa (limpa o hist√≥rico)."""
    try:
        convo.history.clear()
        return jsonify({"status": "success", "message": "Conversa reiniciada."})
    except Exception as e:
        return jsonify({"error": f"Erro ao reiniciar: {e}"}), 500

# ============================================================
# üöÄ EXECU√á√ÉO
# ============================================================

@app.route('/')
def home():
    return render_template('index.html')


if __name__ == '__main__':
    app.run(debug=True, port=5000)
